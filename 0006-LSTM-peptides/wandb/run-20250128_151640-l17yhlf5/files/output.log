Using configuration: {'epochs': 20, 'batch_size': 256, 'learning_rate': 1e-05, 'layers': 4, 'output_size': 22, 'hidden_size': 256, 'dropout': 0.2}
longest peptide: 30 AA
Size of peptides for model: 30
Total peptides: 14220
Training set size: 12087
Test set size: 2133
Max index: 21, Vocab size: 22

-------Starting Training-------
_________________________________
Epoch [1/20]: 100%|██████████████████████████████████████████| 47/47 [00:26<00:00,  1.78it/s, accuracy=tensor(0.0251), loss=3.09]
Epoch [1/20], Loss: 3.098838192351321, Accuracy: 0.02337731420993805
Epoch [2/20]: 100%|██████████████████████████████████████████| 47/47 [00:24<00:00,  1.95it/s, accuracy=tensor(0.3904), loss=3.06]
Epoch [2/20], Loss: 3.0729888094232436, Accuracy: 0.10512197017669678
Epoch [3/20]: 100%|██████████████████████████████████████████| 47/47 [00:24<00:00,  1.93it/s, accuracy=tensor(0.4883), loss=2.99]
Epoch [3/20], Loss: 3.0277778899416012, Accuracy: 0.47966909408569336
Epoch [4/20]: 100%|██████████████████████████████████████████| 47/47 [00:24<00:00,  1.92it/s, accuracy=tensor(0.4758), loss=2.48]
Epoch [4/20], Loss: 2.82551523979674, Accuracy: 0.4881781041622162
Epoch [5/20]: 100%|██████████████████████████████████████████| 47/47 [00:24<00:00,  1.91it/s, accuracy=tensor(0.4856), loss=1.98]
Epoch [5/20], Loss: 2.085700938042174, Accuracy: 0.48728686571121216
Epoch [6/20]: 100%|██████████████████████████████████████████| 47/47 [00:24<00:00,  1.92it/s, accuracy=tensor(0.4916), loss=1.95]
Epoch [6/20], Loss: 1.9635180818273665, Accuracy: 0.48750460147857666
Epoch [7/20]: 100%|██████████████████████████████████████████| 47/47 [00:24<00:00,  1.91it/s, accuracy=tensor(0.4873), loss=1.93]
Epoch [7/20], Loss: 1.9386916135219818, Accuracy: 0.48786285519599915
Epoch [8/20]: 100%|███████████████████████████████████████████| 47/47 [00:24<00:00,  1.92it/s, accuracy=tensor(0.4824), loss=1.9]
Epoch [8/20], Loss: 1.9183734528561855, Accuracy: 0.4884389638900757
Epoch [9/20]:  83%|███████████████████████████████████▋       | 39/47 [00:20<00:04,  1.90it/s, accuracy=tensor(0.4892), loss=1.9]
Traceback (most recent call last):
  File "/Users/igorgonteri/Desktop/Nornour/0006-LSTM-peptides/LSTM-peptide-model.py", line 484, in <module>
    train(train_data, model)
  File "/Users/igorgonteri/Desktop/Nornour/0006-LSTM-peptides/LSTM-peptide-model.py", line 387, in train
    loss, accuracy = model.training_step(x, y, criterion)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/igorgonteri/Desktop/Nornour/0006-LSTM-peptides/LSTM-peptide-model.py", line 333, in training_step
    y_pred, (state_h, state_c) = self(x, (state_h, state_c))
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/LLM2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/LLM2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/igorgonteri/Desktop/Nornour/0006-LSTM-peptides/LSTM-peptide-model.py", line 318, in forward
    logits = self.fc(output)
             ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/LLM2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/LLM2/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/LLM2/lib/python3.11/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
